

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to use DrEvalPy &mdash; DrEvalPy 1.2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/custom_cookietemple.css?v=a7e27724" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=928db92d"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Run your own model" href="runyourmodel.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html">
            
              <img src="_static/drevalpy.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">How to use DrEvalPy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#generate-results-with-run-suite-py">Generate results with <code class="docutils literal notranslate"><span class="pre">run_suite.py</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#visualize-results-with-create-report-py">Visualize results with <code class="docutils literal notranslate"><span class="pre">create_report.py</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#available-settings">Available Settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#available-models">Available Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#available-datasets">Available Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-datasets">Custom Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#available-randomization-tests">Available Randomization Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="#robustness-test">Robustness Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="#available-metrics">Available Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#available-response-transformations">Available Response Transformations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="runyourmodel.html">Run your own model</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">How to cite</a></li>
<li class="toctree-l1"><a class="reference internal" href="API.html">API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">DrEvalPy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">How to use DrEvalPy</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/daisybio/drevalpy/blob/development/docs/usage.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="how-to-use-drevalpy">
<h1>How to use DrEvalPy<a class="headerlink" href="#how-to-use-drevalpy" title="Link to this heading"></a></h1>
<p>Here, we document how to run DrEval with our implemented models and datasets. You can either do this with the standalone
supplied here or with the associated Nextflow pipeline. We recommend the use of our nextflow pipeline for computational
demanding runs and for improved reproducibility.
No knowledge of nextflow is required to run it. The nextflow pipeline is available on the <a class="reference external" href="https://github.com/nf-core/drugresponseeval.git">nf-core GitHub</a>, the corresponding documentation can be found
<a class="reference external" href="https://nf-co.re/drugresponseeval/dev/">here</a>. Documentation of the standalone is provided below.</p>
<section id="generate-results-with-run-suite-py">
<h2>Generate results with <code class="docutils literal notranslate"><span class="pre">run_suite.py</span></code><a class="headerlink" href="#generate-results-with-run-suite-py" title="Link to this heading"></a></h2>
<p>The main script to run the standalone is <code class="docutils literal notranslate"><span class="pre">run_suite.py</span></code>. You can run it with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>run_suite.py<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>--run_id<span class="w"> </span>RUN_ID<span class="o">]</span><span class="w"> </span><span class="o">[</span>--path_data<span class="w"> </span>PATH_DATA<span class="o">]</span><span class="w"> </span><span class="o">[</span>--models<span class="w"> </span>MODELS<span class="w"> </span><span class="o">[</span>MODELS<span class="w"> </span>...<span class="o">]]</span><span class="w"> </span><span class="o">[</span>--baselines<span class="w"> </span>BASELINES<span class="w"> </span><span class="o">[</span>BASELINES<span class="w"> </span>...<span class="o">]]</span><span class="w"> </span><span class="o">[</span>--test_mode<span class="w"> </span>TEST_MODE<span class="w"> </span><span class="o">[</span>TEST_MODE<span class="w"> </span>...<span class="o">]]</span>
<span class="w">                </span><span class="o">[</span>--randomization_mode<span class="w"> </span>RANDOMIZATION_MODE<span class="w"> </span><span class="o">[</span>RANDOMIZATION_MODE<span class="w"> </span>...<span class="o">]]</span><span class="w"> </span><span class="o">[</span>--randomization_type<span class="w"> </span>RANDOMIZATION_TYPE<span class="o">]</span><span class="w"> </span><span class="o">[</span>--n_trials_robustness<span class="w"> </span>N_TRIALS_ROBUSTNESS<span class="o">]</span><span class="w"> </span><span class="o">[</span>--dataset_name<span class="w"> </span>DATASET_NAME<span class="o">]</span>
<span class="w">                </span><span class="o">[</span>--cross_study_datasets<span class="w"> </span>CROSS_STUDY_DATASETS<span class="w"> </span><span class="o">[</span>CROSS_STUDY_DATASETS<span class="w"> </span>...<span class="o">]]</span><span class="w"> </span><span class="o">[</span>--path_out<span class="w"> </span>PATH_OUT<span class="o">]</span><span class="w"> </span><span class="o">[</span>--measure<span class="w"> </span>MEASURE<span class="o">]</span><span class="w"> </span><span class="o">[</span>--curve_curator<span class="o">]</span><span class="w"> </span><span class="o">[</span>--curve_curator_cores<span class="w"> </span>CORES<span class="o">]</span><span class="w"> </span><span class="o">[</span>--overwrite<span class="o">]</span><span class="w"> </span><span class="o">[</span>--optim_metric<span class="w"> </span>OPTIM_METRIC<span class="o">]</span><span class="w"> </span><span class="o">[</span>--n_cv_splits<span class="w"> </span>N_CV_SPLITS<span class="o">]</span>
<span class="w">                </span><span class="o">[</span>--response_transformation<span class="w"> </span>RESPONSE_TRANSFORMATION<span class="o">]</span><span class="w"> </span><span class="o">[</span>--multiprocessing<span class="o">]</span>
</pre></div>
</div>
<p>Options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-h,</span> <span class="pre">--help</span></code>: Show help message and exit.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--run_id</span> <span class="pre">RUN_ID</span></code>: Identifier for the run. Will be used as a prefix for all output files.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--path_data</span> <span class="pre">PATH_DATA</span></code>: Path to the data directory. All data files should be stored in this directory and will be downloaded into this directory. The location of the datasets are resolved by <code class="docutils literal notranslate"><span class="pre">&lt;path_data&gt;/&lt;dataset_name&gt;/&lt;dataset_name&gt;.csv</span></code>. If providing raw viability data, the file needs to be named <code class="docutils literal notranslate"><span class="pre">&lt;dataset_name&gt;_raw.csv</span></code> instead and <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> needs to be specified for automated curve fitting (see <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> for details and also check the <a class="reference internal" href="#custom-datasets"><span class="std std-ref">Custom Datasets</span></a> section).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--models</span> <span class="pre">MODELS</span> <span class="pre">[MODELS</span> <span class="pre">...]</span></code>: List of models to evaluate. For a list of available models, see the <a class="reference internal" href="#available-models"><span class="std std-ref">Available Models</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--baselines</span> <span class="pre">BASELINES</span> <span class="pre">[BASELINES</span> <span class="pre">...]</span></code>: List of baselines to evaluate. For a list of available baselines, see the <a class="reference internal" href="#available-models"><span class="std std-ref">Available Models</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--test_mode</span> <span class="pre">TEST_MODE</span> <span class="pre">[TEST_MODE</span> <span class="pre">...]</span></code>: Which tests to run (LPO=Leave-random-Pairs-Out, LCO=Leave-Cell-line-Out, LDO=Leave-Drug-Out). Can be a list of test runs e.g. ‘LPO LCO LDO’ to run all tests. Default is LPO. For more information, see the <a class="reference internal" href="#available-settings"><span class="std std-ref">Available Settings</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--randomization_mode</span> <span class="pre">RANDOMIZATION_MODE</span> <span class="pre">[RANDOMIZATION_MODE</span> <span class="pre">...]</span></code>: Which randomization mode to use. Can be a list of randomization modes e.g. ‘SVCC SVCD SVRC SVRD’ to run all randomization modes. Default is None. For more information, see the <a class="reference internal" href="#available-randomization-tests"><span class="std std-ref">Available Randomization Tests</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--randomization_type</span> <span class="pre">RANDOMIZATION_TYPE</span></code>: Which randomization type to use. Default is ‘permutation’. For more information, see the <a class="reference internal" href="#available-randomization-tests"><span class="std std-ref">Available Randomization Tests</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--n_trials_robustness</span> <span class="pre">N_TRIALS_ROBUSTNESS</span></code>: Number of trials for robustness testing. Default is 0, which means no robustness testing. For more information, see the <a class="reference internal" href="#robustness-test"><span class="std std-ref">Robustness Test</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--dataset_name</span> <span class="pre">DATASET_NAME</span></code>: Name of the dataset to use. For a list of available datasets, see the <a class="reference internal" href="#available-datasets"><span class="std std-ref">Available Datasets</span></a> section. For information on how to use custom datasets, see the <a class="reference internal" href="#custom-datasets"><span class="std std-ref">Custom Datasets</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--cross_study_datasets</span> <span class="pre">CROSS_STUDY_DATASETS</span> <span class="pre">[CROSS_STUDY_DATASETS</span> <span class="pre">...]</span></code>: List of datasets to use for cross-study validation. For a list of available datasets, see the <a class="reference internal" href="#available-datasets"><span class="std std-ref">Available Datasets</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--path_out</span> <span class="pre">PATH_OUT</span></code>: Path to the output directory. All output files will be stored in this directory.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--measure</span> <span class="pre">MEASURE</span></code>: The name of the measure to use, default ‘LN_IC50’. If using one of the available datasets (see <code class="docutils literal notranslate"><span class="pre">--dataset_name</span></code>), this is restricted to one of [‘LN_IC50’, ‘EC50’, ‘IC50’, ‘pEC50’, ‘AUC’, ‘response’]. This corresponds to the names of the columns that contain theses measures in the provided input dataset. If providing a custom dataset, this may differ. If the option <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> is set, the prefix ‘_curvecurator’ is automatically appended, e.g. ‘LN_IC50_curvecurator’, to allow using the refit measures instead of the ones originally published for the available datasets, allowing for better dataset comparability (refit measures are already provided in the available datasets or computed as part of the fitting procedure when providing custom raw viability datasets, see <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> for details).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code>: If set, the measure is appended with ‘_curvecurator’. If a custom dataset_name was provided, this will invoke the fitting procedure of raw viability data, which is expected to exist at <code class="docutils literal notranslate"><span class="pre">&lt;path_data&gt;/&lt;dataset_name&gt;/&lt;dataset_name&gt;_raw.csv</span></code>. The fitted dataset will be stored in the same folder, in a file called <code class="docutils literal notranslate"><span class="pre">&lt;dataset_name&gt;.csv</span></code>. Also check the <a class="reference internal" href="#custom-datasets"><span class="std std-ref">Custom Datasets</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--curve_curator_cores</span> <span class="pre">CORES</span></code>: Number of cores to use for CurveCurator fitting. Only used when <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> is set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--overwrite</span></code>: If set, existing files will be overwritten.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--optim_metric</span> <span class="pre">OPTIM_METRIC</span></code>: The metric to optimize for during hyperparameter tuning. Default is ‘R^2’. For more information, see the <a class="reference internal" href="#available-metrics"><span class="std std-ref">Available Metrics</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--n_cv_splits</span> <span class="pre">N_CV_SPLITS</span></code>: Number of cross-validation splits. Default is 7.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--response_transformation</span> <span class="pre">RESPONSE_TRANSFORMATION</span></code>: Transformation to apply to the response data. Default is None. For more information, see the <a class="reference internal" href="#available-response-transformations"><span class="std std-ref">Available Response Transformations</span></a> section.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--multiprocessing</span></code>: If set, multiprocessing will be used. Default is False.</p></li>
</ul>
</section>
<section id="visualize-results-with-create-report-py">
<h2>Visualize results with <code class="docutils literal notranslate"><span class="pre">create_report.py</span></code><a class="headerlink" href="#visualize-results-with-create-report-py" title="Link to this heading"></a></h2>
<p>Executing the <code class="docutils literal notranslate"><span class="pre">run_suite.py</span></code> script will generate a folder with the results which includes the predictions of all models
in all specified settings. The <code class="docutils literal notranslate"><span class="pre">create_report.py</span></code> will evaluate the results with all available metrics and create an
HTML report with many visualizations. You can run it with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>create_report.py<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span>--run_id<span class="w"> </span>RUN_ID
</pre></div>
</div>
<p>Options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-h,</span> <span class="pre">--help</span></code>: Show help message and exit.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--run_id</span> <span class="pre">RUN_ID</span></code>: Identifier for the run which was used when executing the <code class="docutils literal notranslate"><span class="pre">run_suite.py</span></code> script.</p></li>
</ul>
<p>The report will be stored in the <code class="docutils literal notranslate"><span class="pre">results/RUN_ID</span></code> folder.
You can open the <code class="docutils literal notranslate"><span class="pre">index.html</span></code> file in your browser to view the report.</p>
</section>
<section id="available-settings">
<h2>Available Settings<a class="headerlink" href="#available-settings" title="Link to this heading"></a></h2>
<p>DrEval is designed to ensure that drug response prediction models are evaluated in a consistent and
reproducible manner. We offer three settings via the <code class="docutils literal notranslate"><span class="pre">--test_mode</span></code> parameter:</p>
<a class="reference internal image-reference" href="_images/LPO.png"><img alt="Image visualizing the Leave-Pair-Out setting" src="_images/LPO.png" style="width: 25%;" />
</a>
<a class="reference internal image-reference" href="_images/LCO.png"><img alt="Image visualizing the Leave-Cell-Line-Out setting" src="_images/LCO.png" style="width: 25%;" />
</a>
<a class="reference internal image-reference" href="_images/LDO.png"><img alt="Image visualizing the Leave-Drug-Out setting" src="_images/LDO.png" style="width: 25%;" />
</a>
<ul class="simple">
<li><p><strong>Leave-Pair-Out (LPO)</strong>: Random pairs of cell lines and drugs are left out for validation/testing but both the drug and the
cell line might already be present in the training set. This is the <strong>easiest setting</strong> for your model but also the
most uninformative one. The only application scenario for this setting is when you want to test whether your model
can <strong>complete the missing values in the training set</strong>.</p></li>
<li><p><strong>Leave-Cell-Line-Out (LCO)</strong>: Random cell lines are left out for validation/testing but the drugs might already be present in
the training set. This setting is <strong>more challenging</strong> than LPO but still relatively easy. The application scenario
for this setting is when you want to test whether your model can <strong>predict the response of a new cell line</strong>. This
is very relevant for <strong>personalized medicine or drug repurposing</strong>.</p></li>
<li><p><strong>Leave-Drug-Out (LDO)</strong>: Random drugs are left out for validation/testing but the cell lines might already be present in the
training set. This setting is the <strong>most challenging</strong> one. The application scenario for this setting is when you
want to test whether your model can <strong>predict the response of a new drug</strong>. This is very relevant for <strong>drug
development</strong>.</p></li>
</ul>
<p>An underlying issue is that drugs have a rather unique IC50 range. That means that by just predicting the mean IC50
that a drug has in the training set (aggregated over all cell lines), you can already achieve a rather good
prediction. This is why we also offer the possibility to compare your model to a <strong>NaivePredictor</strong> that predicts
the mean IC50 of all drugs in the training set. We also offer two more advanced naive predictors:
<strong>NaiveCellLineMeanPredictor</strong> and <strong>NaiveDrugMeanPredictor</strong>. The former predicts the mean IC50 of a cell line in
the training set and the latter predicts the mean IC50 of a drug in the training set.
Finally, as the strongest naive baseline we offer the <strong>NaiveMeanEffectPredictor</strong>
which combines the effects of cell lines and drugs.
It is equivalent to the <strong>NaiveCellLineMeanPredictor</strong> and <strong>NaiveDrugMeanPredictor</strong> for the LDO and LPO settings, respectively.</p>
</section>
<section id="available-models">
<h2>Available Models<a class="headerlink" href="#available-models" title="Link to this heading"></a></h2>
<p>In addition to the Naive Predictors, we offer a variety of more advanced <strong>baseline models</strong> and
some <strong>state-of-the-art models</strong> to compare your model against. You can either set them as baselines or as models via the
<code class="docutils literal notranslate"><span class="pre">--models</span></code> and <code class="docutils literal notranslate"><span class="pre">--baselines</span></code> parameters.
We first identify the best hyperparameters for all models and baselines in a cross-validation setting. Then, we
train the models on the whole training set and evaluate them on the test set.
For <code class="docutils literal notranslate"><span class="pre">--models</span></code>, you can also perform randomization and robustness tests. The <code class="docutils literal notranslate"><span class="pre">--baselines</span></code> are skipped for these tests.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Model Name</p></th>
<th class="head"><p>Baseline / Published Model</p></th>
<th class="head"><p>Multi-Drug Model / Single-Drug Model</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>NaivePredictor</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Most simple method. Predicts the mean response of all drugs in the training set.</p></td>
</tr>
<tr class="row-odd"><td><p>NaiveCellLineMeanPredictor</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Predicts the mean response of a cell line in the training set.</p></td>
</tr>
<tr class="row-even"><td><p>NaiveDrugMeanPredictor</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Predicts the mean response of a drug in the training set.</p></td>
</tr>
<tr class="row-odd"><td><p>NaiveMeanEffectPredictor</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Predicts using ANOVA-like mean effect model of cell lines and drugs</p></td>
</tr>
<tr class="row-even"><td><p>ElasticNet</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Fits an <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html">Sklearn Elastic Net</a>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html">Lasso</a>, or <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html">Ridge</a> model on gene expression data and drug fingerprints (concatenated input matrix).</p></td>
</tr>
<tr class="row-odd"><td><p>GradientBoosting</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Fits an <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html">Sklearn Gradient Boosting Regressor</a> gene expression data and drug fingerprints.</p></td>
</tr>
<tr class="row-even"><td><p>RandomForest</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Fits an <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">Sklearn Random Forest Regressor</a> on gene expression data and drug fingerprints.</p></td>
</tr>
<tr class="row-odd"><td><p>MultiOmicsRandomForest</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Fits an <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">Sklearn Random Forest Regressor</a> on gene expression, methylation, mutation, copy number variation data, and drug fingerprints (concatenated matrix). The dimensionality of the methylation data is reduced with a PCA to the first 100 components before it is fed to the model.</p></td>
</tr>
<tr class="row-even"><td><p>SingleDrugRandomForest</p></td>
<td><p>Baseline Method</p></td>
<td><p>Single-Drug Model</p></td>
<td><p>Fits an <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">Sklearn Random Forest Regressor</a> on gene expression data for each drug separately.</p></td>
</tr>
<tr class="row-odd"><td><p>SVR</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Fits an <a class="reference external" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVR.html">Sklearn Support Vector Regressor</a> gene expression data and drug fingerprints.</p></td>
</tr>
<tr class="row-even"><td><p>SimpleNeuralNetwork</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Fits a simple feedforward neural network (implemented with <a class="reference external" href="https://lightning.ai/docs/pytorch/stable/">Pytorch Lightning</a>) on gene expression and drug fingerprints (concatenated input) with 3 layers of varying dimensions and Dropout layers.</p></td>
</tr>
<tr class="row-odd"><td><p>MultiOmicsNeuralNetwork</p></td>
<td><p>Baseline Method</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p>Fits a simple feedforward neural network (implemented with <a class="reference external" href="https://lightning.ai/docs/pytorch/stable/">Pytorch Lightning</a>) on gene expression, methylation, mutation, copy number variation data, and drug fingerprints (concatenated input) with 3 layers of varying dimensions and Dropout layers. The dimensionality of the methylation data is reduced with a PCA to the first 100 components before it is fed to the model.</p></td>
</tr>
<tr class="row-even"><td><p>SRMF</p></td>
<td><p>Published Model</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p><a class="reference external" href="https://doi.org/10.1186/s12885-017-3500-5">Similarity Regularization Matrix Factorization</a> model by Wang et al. on gene expression data and drug fingerprints. Re-implemented Matlab code into Python. The basic idea is represent each drug and each cell line by their respective similarities to all other drugs/cell lines. Those similarities are mapped into a shared latent low-dimensional space from which responses are predicted.</p></td>
</tr>
<tr class="row-odd"><td><p>MOLIR</p></td>
<td><p>Published Model</p></td>
<td><p>Single-Drug Model</p></td>
<td><p>Regression extension of <a class="reference external" href="https://doi.org/10.1093/bioinformatics/btz318">MOLI: multi-omics late integration deep neural network.</a> by Sharifi-Noghabi et al. Takes somatic mutation, copy number variation and gene expression data as input. MOLI reduces the dimensionality of each omics type with a hidden layer, concatenates them into one representation and optimizes this representation via a combined cost function consisting of a triplet loss and a binary cross-entropy loss. We implemented a regression adaption with MSE loss and an adapted triplet loss for regression.</p></td>
</tr>
<tr class="row-even"><td><p>SuperFELTR</p></td>
<td><p>Published Model</p></td>
<td><p>Single-Drug Model</p></td>
<td><p>Regression extension of <a class="reference external" href="https://doi.org/10.1186/s12859-021-04146-z">SuperFELT: supervised feature extraction learning using triplet loss for drug response</a> by Park et al. Very similar to MOLI(R). In MOLI(R), encoders and the classifier were trained jointly. Super.FELT(R) trains them independently. MOLI(R) was trained without feature selection (except for the Variance Threshold on the gene expression). Super.FELT(R) uses feature selection for all omics data.</p></td>
</tr>
<tr class="row-odd"><td><p>DIPK</p></td>
<td><p>Published Model</p></td>
<td><p>Multi-Drug Model</p></td>
<td><p><a class="reference external" href="https://doi.org/10.1093/bib/bbae153">Deep neural network Integrating Prior Knowledge</a> from Li et al. Uses gene interaction relationships (encoded by a graph auto-encoder), gene expression profiles (encoded by a denoising auto-encoder), and molecular topologies (encoded by MolGNet). Those features are integrated using multi-head attention layers.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="available-datasets">
<h2>Available Datasets<a class="headerlink" href="#available-datasets" title="Link to this heading"></a></h2>
<p>We provide commonly used datasets to evaluate your model on (GDSC1, GDSC2, CCLE, CTRPv2) via the <code class="docutils literal notranslate"><span class="pre">--dataset_name</span></code> parameter.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Dataset Name</p></th>
<th class="head"><p>Number of Drugs</p></th>
<th class="head"><p>Number of Cell Lines</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>GDSC1</p></td>
<td><p>378</p></td>
<td><p>970</p></td>
<td><p>The Genomics of Drug Sensitivity in Cancer (GDSC) dataset version 1.</p></td>
</tr>
<tr class="row-odd"><td><p>GDSC2</p></td>
<td><p>287</p></td>
<td><p>969</p></td>
<td><p>The Genomics of Drug Sensitivity in Cancer (GDSC) dataset version 2.</p></td>
</tr>
<tr class="row-even"><td><p>CCLE</p></td>
<td><p>24</p></td>
<td><p>503</p></td>
<td><p>The Cancer Cell Line Encyclopedia (CCLE) dataset.</p></td>
</tr>
<tr class="row-odd"><td><p>CTRPv1</p></td>
<td><p>354</p></td>
<td><p>243</p></td>
<td><p>The Cancer Therapeutics Response Portal (CTRP) dataset version 1.</p></td>
</tr>
<tr class="row-even"><td><p>CTRPv2</p></td>
<td><p>546</p></td>
<td><p>886</p></td>
<td><p>The Cancer Therapeutics Response Portal (CTRP) dataset version 2.</p></td>
</tr>
<tr class="row-odd"><td><p>TOYv1</p></td>
<td><p>36</p></td>
<td><p>90</p></td>
<td><p>A toy dataset for testing purposes subsetted from CTRPv2.</p></td>
</tr>
<tr class="row-even"><td><p>TOYv2</p></td>
<td><p>36</p></td>
<td><p>90</p></td>
<td><p>A second toy dataset for cross study testing purposes. 80 cell lines and 32 drugs overlap TOYv2.</p></td>
</tr>
</tbody>
</table>
<p>If using the <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> option with these datasets, the desired measure provided with the <code class="docutils literal notranslate"><span class="pre">--measure</span></code> option is appended with “_curvecurator”, e.g. “IC50_curvecurator”.
In the provided datasets, these are the measures calculated with the same fitting procedure using CurveCurator. To use the measures reported from the original publications of the
dataset, do not set the <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> option.</p>
<p>This however makes it hard to do cross-study comparisons, since the measures may not be directly comparable due to differences in the fitting procedures used by the original authors.
It is therefore recommended to always use DrEvalPy with the <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> option, even when providing your own custom datasets (see next section).</p>
</section>
<section id="custom-datasets">
<h2>Custom Datasets<a class="headerlink" href="#custom-datasets" title="Link to this heading"></a></h2>
<p>You can also provide your own custom dataset via the <code class="docutils literal notranslate"><span class="pre">--dataset_name</span></code> parameter by specifying a name that is not in the list of the available datasets.
This can be prefit data (not recommended for comparability reasons) or raw viability data that is automatically fit with the exact same procedure that was used to refit
the available datasets in the previous section.</p>
<p><strong>Raw viability data</strong></p>
<ul class="simple">
<li><p>DrEvalPy expects a csv-formatted file in the location <code class="docutils literal notranslate"><span class="pre">&lt;path_data&gt;/&lt;dataset&gt;/&lt;dataset_name&gt;_raw.csv</span></code> (corresponding to the <code class="docutils literal notranslate"><span class="pre">--path_data</span></code> and <code class="docutils literal notranslate"><span class="pre">--dataset_name</span></code> options),
which contains the raw viability data in long format with the columns [“dose”, “response”, “sample”, “drug”] and an optional “replicate” column.
If replicates are provided, the procedure will fit one curve per sample / drug pair using all replicates.</p></li>
<li><p>The options <code class="docutils literal notranslate"><span class="pre">--curve_curator</span></code> and <code class="docutils literal notranslate"><span class="pre">--curve_curator_cores</span></code> must be set.</p></li>
<li><p>Available measures are [“AUC”, “pEC50”, “EC50”, “IC50”].</p></li>
<li><p>DrEvalPy provides all results of the fitting in the same folder including the fitted curves in a file folder <code class="docutils literal notranslate"><span class="pre">&lt;path_data&gt;/&lt;dataset&gt;/&lt;dataset_name&gt;.csv</span></code></p></li>
</ul>
<p><strong>Prefit viability data</strong></p>
<ul class="simple">
<li><p>DrEvalPy expects a csv-formatted file in the location <code class="docutils literal notranslate"><span class="pre">&lt;path_data&gt;/&lt;dataset&gt;/&lt;dataset_name&gt;.csv</span></code> (corresponding to the <code class="docutils literal notranslate"><span class="pre">--path_data</span></code> and <code class="docutils literal notranslate"><span class="pre">--dataset_name</span></code> options),
with at least the columns [“cell_line_id”, “drug_id”, &lt;measure&gt;”] where &lt;measure&gt; is replaced with the name of the measure you provide</p></li>
<li><p>Available measures depend on the column names and can be provided using the <cite>–measure</cite> option.</p></li>
<li><p>It is required that you use measure names that are also working with the available datasets if you use the <code class="docutils literal notranslate"><span class="pre">--cross_study_datasets</span></code> option</p></li>
</ul>
</section>
<section id="available-randomization-tests">
<h2>Available Randomization Tests<a class="headerlink" href="#available-randomization-tests" title="Link to this heading"></a></h2>
<p>We offer the possibility to test how much the performance of your model deteriorates when you randomize the input training data.
We have several randomization modes and types available.</p>
<p>The modes are supplied via <code class="docutils literal notranslate"><span class="pre">--randomization_mode</span></code> and the types via <code class="docutils literal notranslate"><span class="pre">--randomization_type</span></code>.:</p>
<ul class="simple">
<li><p><strong>SVCC: Single View Constant for Cell Lines:</strong> A single cell line view (e.g., gene expression) is held unperturbed
while the others are randomized.</p></li>
<li><p><strong>SVCD: Single View Constant for Drugs:</strong> A single drug view (e.g., drug fingerprints) is held unperturbed while the
others are randomized.</p></li>
<li><p><strong>SVRC: Single View Random for Cell Lines:</strong> A single cell line view (e.g., gene expression) is randomized while the
others are held unperturbed.</p></li>
<li><p><strong>SVRD: Single View Random for Drugs:</strong> A single drug view (e.g., drug fingerprints) is randomized while the others
are held unperturbed.</p></li>
</ul>
<p>Currently, we support two ways of randomizing the data. The default is permututation.</p>
<ul class="simple">
<li><p><strong>Permutation</strong>: Permutes the features over the instances, keeping the distribution of the features the same but
dissolving the relationship to the target.</p></li>
<li><p><strong>Invariant</strong>: The randomization is done in a way that a key characteristic of the feature is preserved. In case
of matrices, this is the mean and standard deviation of the feature view for this instance, for networks it is the
degree distribution.</p></li>
</ul>
</section>
<section id="robustness-test">
<h2>Robustness Test<a class="headerlink" href="#robustness-test" title="Link to this heading"></a></h2>
<p>The robustness test is a test where the model is trained with varying seeds. This is done multiple times to see how
stable the model is. Via <code class="docutils literal notranslate"><span class="pre">--n_trials_robustness</span></code>, you can specify the number of trials for the robustness tests.</p>
<p><em>Note</em>: You need at least 7 trials to get a meaningful critical difference diagram and the corresponding p-values.</p>
</section>
<section id="available-metrics">
<h2>Available Metrics<a class="headerlink" href="#available-metrics" title="Link to this heading"></a></h2>
<p>We offer a variety of metrics to evaluate your model on. The default is the R^2 score. You can change the metric via
the <code class="docutils literal notranslate"><span class="pre">--optim_metric</span></code> parameter. The following metrics are available:</p>
<ul class="simple">
<li><p><strong>R^2</strong>: The coefficient of determination. The higher the better.</p></li>
<li><p><strong>MSE</strong>: The mean squared error. The lower the better.</p></li>
<li><p><strong>RMSE</strong>: The root mean squared error. The lower the better.</p></li>
<li><p><strong>MAE</strong>: The mean absolute error. The lower the better.</p></li>
<li><p><strong>Pearson</strong>: The Pearson correlation coefficient. The higher the better.</p></li>
<li><p><strong>Spearman</strong>: The Spearman correlation coefficient. The higher the better.</p></li>
<li><p><strong>Kendall</strong>: The Kendall correlation coefficient. The higher the better.</p></li>
<li><p><strong>Partial_Correlation</strong>: The partial correlation coefficient which corrects for the drug and cell line effects. The higher the better.</p></li>
</ul>
</section>
<section id="available-response-transformations">
<h2>Available Response Transformations<a class="headerlink" href="#available-response-transformations" title="Link to this heading"></a></h2>
<p>We offer the possibility to transform the response data before training the model. This can be done via the
<code class="docutils literal notranslate"><span class="pre">--response_transformation</span></code> parameter. The following transformations are available:</p>
<ul class="simple">
<li><p><strong>None</strong>: No transformation is applied.</p></li>
<li><p><strong>standard</strong>: The <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">sklearn StandardScaler</a> is applied.</p></li>
<li><p><strong>minmax</strong>: The <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html">sklearn MinMaxScaler</a> is applied.</p></li>
<li><p><strong>robust</strong>: The <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html">sklearn RobustScaler</a> is applied.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="runyourmodel.html" class="btn btn-neutral float-right" title="Run your own model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, DaiSyBio at Technical University of Munich.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>