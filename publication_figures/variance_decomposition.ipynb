{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "\n",
    "def get_results_and_drug_vis(algorithm, sample, test_mode, normalized):\n",
    "\n",
    "    t_vs_p_path = None\n",
    "    if test_mode == \"LPO\":\n",
    "        t_vs_p_path = 'to_the_universe_new/true_vs_pred.csv'\n",
    "    elif test_mode == \"LCO\":\n",
    "        t_vs_p_path = 'to_the_stars/true_vs_pred.csv'\n",
    "    elif test_mode == \"LDO\":\n",
    "        t_vs_p_path = 'ldo_results/true_vs_pred.csv'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid test mode\")\n",
    "    results = pd.read_csv(t_vs_p_path, dtype={\"drug\": str, \"cell_line\": str, \"CV_split\": int})\n",
    "    results = results[results['rand_setting'] ==\"predictions\"]\n",
    "    results = results[results['algorithm'] ==algorithm]\n",
    "    # Load drug name mapping\n",
    "    pubchem_id_to_drugname = pd.read_csv('../data/CTRPv2/drug_names.csv')\n",
    "\n",
    "\n",
    "    if sample == \"picked\":\n",
    "        viz_drugs = [\"bafilomycin A1\", \"chlorambucil\", \"NSC 74859\",\"hyperforin\", \"Docetaxel\", \"C6-ceramide\", \"obatoclax\", \"Entinostat\", \"etomoxir\"]\n",
    "        pubchem_ids = []\n",
    "        for drug in viz_drugs:\n",
    "            pubchem_ids.append(pubchem_id_to_drugname[pubchem_id_to_drugname['drug_name'] == drug]['pubchem_id'].values[0])\n",
    "        viz_drugs = pubchem_ids\n",
    "    elif sample == \"top\":\n",
    "        viz_drugs = results['drug'].value_counts().index[:10]\n",
    "    elif sample == \"random\":\n",
    "        viz_drugs = results['drug'].unique()\n",
    "        #choose  random drugs\n",
    "        random.seed(42)\n",
    "        viz_drugs = random.sample(list(viz_drugs), 12)\n",
    "    elif sample ==\"lowest_pearson\":\n",
    "\n",
    "        # Compute Pearson correlation per drug\n",
    "        pearsons = results.groupby('drug').apply(lambda g: pearsonr(g['y_true'], g['y_pred'])[0])\n",
    "\n",
    "        # Drop NaNs (in case a drug has constant y_true or y_pred)\n",
    "        pearsons = pearsons.dropna()\n",
    "\n",
    "        # Select 10 drugs with lowest Pearson correlation\n",
    "        viz_drugs = pearsons.nsmallest(50).index.tolist()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sample option\")\n",
    "\n",
    "    # Filter mapping to only include  viz drugs\n",
    "    top_drug_names = pubchem_id_to_drugname[pubchem_id_to_drugname['pubchem_id'].isin(viz_drugs)]\n",
    "\n",
    "    # Create mapping dict\n",
    "    id_to_name = dict(zip(top_drug_names['pubchem_id'], top_drug_names['drug_name']))\n",
    "    results['drug'] = results['drug'].astype(str)\n",
    "    pubchem_id_to_drugname['pubchem_id'] = pubchem_id_to_drugname['pubchem_id'].astype(str)\n",
    "\n",
    "    # Map drug IDs to names, fill with \"Other\" if not in \n",
    "    results[\"drug_name_viz\"] = results['drug'].map(id_to_name).fillna(\"Other\")\n",
    "    if not normalized:\n",
    "        return results\n",
    "    else:\n",
    "\n",
    "        # Load and filter\n",
    "        results2 = pd.read_csv(t_vs_p_path, dtype={\"drug\": str, \"cell_line\": str, \"CV_split\": int}, index_col=0)\n",
    "        results2 = results2[results2[\"rand_setting\"] == \"predictions\"]\n",
    "\n",
    "        # Ensure consistent types\n",
    "        results2[\"drug\"] = results2[\"drug\"].astype(str)\n",
    "        results2[\"cell_line\"] = results2[\"cell_line\"].astype(str)\n",
    "        results2[\"CV_split\"] = results2[\"CV_split\"].astype(int)\n",
    "\n",
    "        # Prepare naive predictions\n",
    "        naive = results2[results2[\"algorithm\"] == \"NaiveMeanEffectsPredictor\"].copy()\n",
    "        naive[\"drug\"] = naive[\"drug\"].astype(str)\n",
    "        naive[\"cell_line\"] = naive[\"cell_line\"].astype(str)\n",
    "        naive[\"CV_split\"] = naive[\"CV_split\"].astype(int)\n",
    "\n",
    "        naive = naive[[\"drug\", \"cell_line\", \"CV_split\", \"y_pred\"]].rename(columns={\"y_pred\": \"naive_y_pred\"})\n",
    "\n",
    "        # Merge\n",
    "        merged = results2.merge(naive, on=[\"drug\", \"cell_line\"], how=\"left\")\n",
    "\n",
    "        # Drop any rows where naive_y_pred is missing (just in case)\n",
    "        merged = merged.dropna(subset=[\"naive_y_pred\"])\n",
    "\n",
    "        # Subtract naive prediction from y_pred and y_true\n",
    "        merged[\"y_pred\"] = merged[\"y_pred\"] - merged[\"naive_y_pred\"]\n",
    "        merged[\"y_true\"] = merged[\"y_true\"] - merged[\"naive_y_pred\"]\n",
    "\n",
    "        merged = merged[merged['algorithm'] ==algorithm]\n",
    "\n",
    "\n",
    "        # Map drug IDs to names, fill with \"Other\" if not in \n",
    "        merged[\"drug_name_viz\"] = merged['drug'].map(id_to_name).fillna(\"Other\")\n",
    "        merged.rename(columns={\"CV_split_x\": \"CV_split\"})\n",
    "        return merged\n",
    "#results_lpo = get_results_and_drug_vis(algorithm=ALGORITHM, sample=SAMPLE, LCO=False, normalized=False)\n",
    "#results_lpo_norm = get_results_and_drug_vis(algorithm=ALGORITHM, sample=SAMPLE, LCO=False, normalized=True)\n",
    "#results_lco = get_results_and_drug_vis(algorithm=ALGORITHM, sample=SAMPLE, LCO=True, normalized=False)\n",
    "#results_lco_norm = get_results_and_drug_vis(algorithm=ALGORITHM, sample=SAMPLE, LCO=True, normalized=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned up version of the code\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def compute_variance_decomposition(y_true, y_pred_rf, y_pred_nm):\n",
    "    tss = np.var(y_true, ddof=0)\n",
    "    rss_rf = np.mean((y_true - y_pred_rf) ** 2)\n",
    "    rss_nm = np.mean((y_true - y_pred_nm) ** 2)\n",
    "    ess_rf = tss - rss_rf\n",
    "    ess_nm = tss - rss_nm\n",
    "    r2_rf = ess_rf / tss\n",
    "    r2_nm = ess_nm / tss\n",
    "    extra_ess = ess_rf - ess_nm\n",
    "    relative_gain = extra_ess / (tss - ess_nm) if (tss - ess_nm) > 0 else 0\n",
    "    unexplained = tss - ess_rf\n",
    "\n",
    "    return {\n",
    "        \"tss\": tss,\n",
    "        \"ess_nm\": ess_nm,\n",
    "        \"ess_rf\": ess_rf,\n",
    "        \"extra_ess\": extra_ess,\n",
    "        \"unexplained\": unexplained,\n",
    "        \"r2_nm\": r2_nm,\n",
    "        \"r2_rf\": r2_rf,\n",
    "        \"relative_gain\": relative_gain\n",
    "    }\n",
    "\n",
    "def plot_variance_decomposition(ax, tss, ess_nm, extra_ess, unexplained, max_tss,\n",
    "                                xlabel=None):\n",
    "    font_adder = 10\n",
    "    components = [ess_nm, extra_ess, unexplained]\n",
    "    colors = ['#999999', '#00BFC4', '#F8766D']\n",
    "    labels = ['Naive', 'RF gain', 'Unexplained']\n",
    "\n",
    "    ax.bar(0, tss, color='white', edgecolor='black', width=0.6)\n",
    "    bottom = 0\n",
    "\n",
    "\n",
    "    for val, label, color in zip(components, labels, colors):\n",
    "        height = val\n",
    "        percent = (val / tss) * 100 if tss > 0 else 0\n",
    "        ax.bar(0, height, bottom=bottom, label=label, color=color, width=0.6)\n",
    "\n",
    "        text_color = 'black'\n",
    "\n",
    "        label_text = f\"{percent:.1f}%\"\n",
    "        label_pos = bottom + height / 2\n",
    "        if height <= 0:\n",
    "            continue\n",
    "        if height > 0.03 * tss:\n",
    "\n",
    "            # Normal in-bar label\n",
    "            ax.text(0, label_pos, label_text,\n",
    "                    ha='center', va='center',\n",
    "                    fontsize=5 + font_adder, fontweight='bold', color=text_color)\n",
    "        else:\n",
    "            # Fallback: draw pointer and write just outside the right edge of the segment\n",
    "            y_outside = bottom + height / 2\n",
    "            ax.text(0.35, y_outside, label_text,\n",
    "                    ha='left', va='center', fontsize=5 + font_adder, fontweight='bold', color='black')\n",
    "\n",
    "\n",
    "        bottom += height\n",
    "    \n",
    "\n",
    "\n",
    "    ax.set_xlim(-0.7, 0.7)\n",
    "    ax.set_ylim(0, max_tss * 1.1)\n",
    "\n",
    "    # Draw short TSS tick in raw variance units\n",
    "    ax.plot([-0.35, -0.25], [tss, tss], color='black', linewidth=1)\n",
    "    ax.text(-0.4, tss, f\"{tss:.2f}\", ha='right', va='center',\n",
    "            fontsize=8 + font_adder, color='black')\n",
    "\n",
    "    ax.set_xticks([0])\n",
    "    ax.set_xticklabels([xlabel] if xlabel else [''])\n",
    "    ax.set_ylabel(\"Variance\", fontsize=10+font_adder)\n",
    "    ax.tick_params(axis='both', labelsize=9+font_adder)\n",
    "\n",
    "def get_model_preds_and_merge(rf_results, nm_results, merge_cols, pred_col_rf='y_pred_rf', pred_col_nm='y_pred_nm'):\n",
    "    try:\n",
    "        rf = rf_results[rf_results.CV_split == 0].copy()\n",
    "        nm = nm_results[nm_results.CV_split == 0].copy()\n",
    "    except AttributeError:\n",
    "        rf = rf_results[rf_results.CV_split_x == 0].copy()\n",
    "        nm = nm_results[nm_results.CV_split_x == 0].copy()\n",
    "\n",
    "    rf = rf.rename(columns={'y_pred': pred_col_rf})\n",
    "    nm = nm.rename(columns={'y_pred': pred_col_nm})\n",
    "\n",
    "    merged = rf.merge(nm[merge_cols + [pred_col_nm]], on=merge_cols, how='inner')\n",
    "    return merged\n",
    "def compute_splitwise_mean_decomposition(rf_df, nm_df):\n",
    "    if 'CV_split' in rf_df.columns and 'CV_split' in nm_df.columns:\n",
    "        split_col = 'CV_split'\n",
    "    elif 'CV_split_x' in rf_df.columns and 'CV_split_x' in nm_df.columns:\n",
    "        split_col = 'CV_split_x'\n",
    "    else:\n",
    "        raise ValueError(\"No CV_split column found.\")\n",
    "\n",
    "    split_ids = sorted(set(rf_df[split_col]) & set(nm_df[split_col]))\n",
    "    metrics_list = []\n",
    "\n",
    "    for split in split_ids:\n",
    "        rf = rf_df[rf_df[split_col] == split].copy()\n",
    "        nm = nm_df[nm_df[split_col] == split].copy()\n",
    "\n",
    "        merged = rf.merge(\n",
    "            nm[['drug', 'cell_line', 'y_pred']],\n",
    "            on=['drug', 'cell_line'],\n",
    "            suffixes=('_rf', '_nm')\n",
    "        )\n",
    "\n",
    "        y_true = merged['y_true'].values\n",
    "        y_pred_rf = merged['y_pred_rf'].values\n",
    "        y_pred_nm = merged['y_pred_nm'].values\n",
    "\n",
    "        metrics = compute_variance_decomposition(y_true, y_pred_rf, y_pred_nm)\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "    # Average each metric\n",
    "    keys = metrics_list[0].keys()\n",
    "    return {k: np.mean([m[k] for m in metrics_list]) for k in keys}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = \"LCO\"\n",
    "SAMPLE = \"picked\"\n",
    "ALGORITHM = \"RandomForest\"\n",
    "\n",
    "\n",
    "\n",
    "# --- Load raw predictions ---\n",
    "rf_raw = get_results_and_drug_vis(algorithm=\"RandomForest\", sample=SAMPLE, test_mode=test_mode, normalized=False)\n",
    "nm_raw = get_results_and_drug_vis(algorithm=\"NaiveMeanEffectsPredictor\", sample=SAMPLE, test_mode=test_mode, normalized=False)\n",
    "merged_raw = get_model_preds_and_merge(rf_raw, nm_raw, merge_cols=['drug', 'cell_line'])\n",
    "\n",
    "# --- Load normalized predictions ---\n",
    "rf_norm = get_results_and_drug_vis(algorithm=\"RandomForest\", sample=SAMPLE, test_mode=test_mode, normalized=True)\n",
    "nm_norm = get_results_and_drug_vis(algorithm=\"NaiveMeanEffectsPredictor\", sample=SAMPLE, test_mode=test_mode, normalized=True)\n",
    "merged_norm = get_model_preds_and_merge(rf_norm, nm_norm, merge_cols=['drug', 'cell_line'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Compute decompositions ---\n",
    "raw_metrics = compute_splitwise_mean_decomposition(rf_raw, nm_raw)\n",
    "norm_metrics = compute_splitwise_mean_decomposition(rf_norm, nm_norm)\n",
    "\n",
    "def safe_components(metrics):\n",
    "    tss = metrics['tss']\n",
    "    ess_nm = max(metrics['ess_nm'], 0)\n",
    "    extra_ess = max(metrics['extra_ess'], 0)\n",
    "    unexplained = max(tss - ess_nm - extra_ess, 0)\n",
    "    return tss, ess_nm, extra_ess, unexplained\n",
    "# --- Print metrics ---\n",
    "def print_metrics(label, metrics):\n",
    "    print(f\"\\n[{label}]\")\n",
    "    print(f\"Total variance (TSS): {metrics['tss']:.4f}\")\n",
    "    print(f\"Naive Mean R²: {metrics['r2_nm']:.4f}\")\n",
    "    print(f\"Random Forest R²: {metrics['r2_rf']:.4f}\")\n",
    "    print(f\"Extra variance explained by RF (ESS): {metrics['extra_ess']:.4f}\")\n",
    "    print(f\"Relative gain over unexplained variance: {metrics['relative_gain']*100:.2f}%\")\n",
    "\n",
    "print_metrics(\"Raw\", raw_metrics)\n",
    "print_metrics(\"Normalized\", norm_metrics)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "max_tss = max(raw_metrics['tss'], norm_metrics['tss'])\n",
    "\n",
    "plot_variance_decomposition(\n",
    "    ax=axes[0],\n",
    "    tss=safe_components(raw_metrics)[0],\n",
    "    ess_nm=safe_components(raw_metrics)[1],\n",
    "    extra_ess=safe_components(raw_metrics)[2],\n",
    "    unexplained=safe_components(raw_metrics)[3],\n",
    "    max_tss=max_tss,\n",
    "    xlabel='Raw',\n",
    ")\n",
    "\n",
    "plot_variance_decomposition(\n",
    "    ax=axes[1],\n",
    "    tss=safe_components(norm_metrics)[0],\n",
    "    ess_nm=safe_components(norm_metrics)[1],\n",
    "    extra_ess=safe_components(norm_metrics)[2],\n",
    "    unexplained=safe_components(norm_metrics)[3],\n",
    "    max_tss=max_tss,\n",
    "    xlabel='Normalized',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "axes[1].legend(loc='upper right', frameon=True, fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figures/variance_decomposition_{test_mode}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
